{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad7cc09",
   "metadata": {},
   "source": [
    "# Installing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ce8124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\adars\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: gspread in c:\\users\\adars\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: oauth2client in c:\\users\\adars\\anaconda3\\lib\\site-packages (4.1.3)\n",
      "Requirement already satisfied: pygsheets in c:\\users\\adars\\anaconda3\\lib\\site-packages (2.0.6)\n",
      "Requirement already satisfied: clipboard in c:\\users\\adars\\anaconda3\\lib\\site-packages (0.0.4)\n",
      "Requirement already satisfied: pyperclip in c:\\users\\adars\\anaconda3\\lib\\site-packages (1.8.2)\n",
      "Requirement already satisfied: pyautogui in c:\\users\\adars\\anaconda3\\lib\\site-packages (0.9.54)\n",
      "Requirement already satisfied: fake_useragent in c:\\users\\adars\\anaconda3\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: undetected_chromedriver in c:\\users\\adars\\anaconda3\\lib\\site-packages (3.4.7)\n",
      "Requirement already satisfied: tld in c:\\users\\adars\\anaconda3\\lib\\site-packages (0.13)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: google-auth>=1.12.0 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from gspread) (2.19.1)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from gspread) (1.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from oauth2client) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from oauth2client) (4.9)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from oauth2client) (0.22.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from oauth2client) (0.4.8)\n",
      "Requirement already satisfied: six>=1.6.1 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from oauth2client) (1.16.0)\n",
      "Requirement already satisfied: google-api-python-client>=2.50.0 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from pygsheets) (2.88.0)\n",
      "Requirement already satisfied: pyscreeze>=0.1.21 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from pyautogui) (0.1.29)\n",
      "Requirement already satisfied: pytweening>=1.0.4 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from pyautogui) (1.0.7)\n",
      "Requirement already satisfied: mouseinfo in c:\\users\\adars\\anaconda3\\lib\\site-packages (from pyautogui) (0.1.3)\n",
      "Requirement already satisfied: pymsgbox in c:\\users\\adars\\anaconda3\\lib\\site-packages (from pyautogui) (1.0.9)\n",
      "Requirement already satisfied: pygetwindow>=0.0.5 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from pyautogui) (0.0.9)\n",
      "Requirement already satisfied: websockets in c:\\users\\adars\\anaconda3\\lib\\site-packages (from undetected_chromedriver) (11.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\adars\\anaconda3\\lib\\site-packages (from undetected_chromedriver) (2.28.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from google-api-python-client>=2.50.0->pygsheets) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from google-api-python-client>=2.50.0->pygsheets) (0.1.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from google-api-python-client>=2.50.0->pygsheets) (2.11.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from google-auth>=1.12.0->gspread) (5.3.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from google-auth-oauthlib>=0.4.1->gspread) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from httplib2>=0.9.1->oauth2client) (3.0.9)\n",
      "Requirement already satisfied: pyrect in c:\\users\\adars\\anaconda3\\lib\\site-packages (from pygetwindow>=0.0.5->pyautogui) (0.2.0)\n",
      "Requirement already satisfied: pyscreenshot in c:\\users\\adars\\anaconda3\\lib\\site-packages (from pyscreeze>=0.1.21->pyautogui) (3.1)\n",
      "Requirement already satisfied: Pillow>=9.2.0 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from pyscreeze>=0.1.21->pyautogui) (9.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\adars\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\adars\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\adars\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in c:\\users\\adars\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from requests->undetected_chromedriver) (2.0.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\adars\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=2.50.0->pygsheets) (1.59.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=2.50.0->pygsheets) (4.23.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: mss in c:\\users\\adars\\anaconda3\\lib\\site-packages (from pyscreenshot->pyscreeze>=0.1.21->pyautogui) (9.0.1)\n",
      "Requirement already satisfied: EasyProcess in c:\\users\\adars\\anaconda3\\lib\\site-packages (from pyscreenshot->pyscreeze>=0.1.21->pyautogui) (1.1)\n",
      "Requirement already satisfied: entrypoint2 in c:\\users\\adars\\anaconda3\\lib\\site-packages (from pyscreenshot->pyscreeze>=0.1.21->pyautogui) (1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium gspread oauth2client pygsheets clipboard pyperclip pyautogui fake_useragent undetected_chromedriver tld\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2dfd09",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bda996d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (Macintosh; U; PPC Mac OS X 10_5_2; en-gb) AppleWebKit/526+ (KHTML, like Gecko) Version/3.1 iPhone\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "#import undetected_chromedriver as uc\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random as rd\n",
    "import threading\n",
    "import subprocess\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException \n",
    "options = Options()\n",
    "options.add_argument(\"window-size=60,20\")\n",
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "print(user_agent)\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "import itertools\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "import urllib.parse\n",
    "from tld import get_tld\n",
    "import argparse\n",
    "import pyautogui\n",
    "import pyperclip\n",
    "import clipboard\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac92115",
   "metadata": {},
   "source": [
    "# Useful info..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07625f9",
   "metadata": {},
   "source": [
    "# parts of URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d058930b",
   "metadata": {},
   "source": [
    "1.Scheme/Protocol\n",
    "\n",
    "2.Subdomain\n",
    "\n",
    "3.Domain\n",
    "\n",
    "4.Top-Level Domain (TLD)\n",
    "\n",
    "5.Port\n",
    "\n",
    "6.Path\n",
    "\n",
    "7.Query Parameters\n",
    "\n",
    "8.Fragment/Anchor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1751ea4e",
   "metadata": {},
   "source": [
    "# Getting the data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe40241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the data into a pandas DataFrame\n",
    "df = pd.read_excel('21.xlsx')\n",
    "df['Home page url/loaded/']=''\n",
    "df['Compliance url/loaded/']=''\n",
    "df['Cat page url/loaded/']=''\n",
    "df['Compliance url.1/loaded/']=''\n",
    "df['Home page url/title/']=''\n",
    "df['Compliance url/title/']=''\n",
    "df['Cat page url/title/']=''\n",
    "df['Compliance url.1/title/']=''\n",
    "#df=df.sort_values(by=['code'],ignore_index=True)\n",
    "geo=pd.read_excel('geoloc.xlsx')\n",
    "# List of monetization parameters to check\n",
    "monetization_perimeters = [\"sscid\", \"src\", \"tagrid\", \"epi\", \"Linkshare\", \"affc\", \"pid\", \"wgu\", \"cjdata\", \"porc\",\n",
    "                           \"utm_source\", \"cfclick\", \"cjevent\", \"awc\", \"utm_medium\", \"utm_campaign\", \"ranMID\", \"MID\",\n",
    "                           \"ranEAID\", \"EAID\", \"irclickid\", \"irgwc\", \"avad\", \"clickId\", \"click_id\", \"affiliate_id\",\n",
    "                           \"utm_content\", \"source\", \"utm_term\", \"ranSiteID\", \"publisherId\", \"vendor\", \"hop\", \"irpid\",\n",
    "                           \"ircid\", \"adid\", \"tagtag_uid\", \"medium\", \"clickid\", \"zanpid\", \"uid\", \"AffiliateID\",\n",
    "                           \"cnxclid\", \"subid\", \"uuid\", \"mkcid\", \"cid\", \"aff_id\", \"ref\", \"belboon\",\n",
    "                           \"AffiliateReferenceID\", \"siteID\", \"SSAID\", \"ncid\", \"CMP\", \"affcid\", \"tduid\",'affid',\n",
    "                           \"__c=1\",\"trac\",\"tt\",\"LSNSUBSITE\",\"CAID\",\"sid\",\"AVGAFFILIATE\",\"aff\",\"partner\",\"sterm\",\"AID\",\n",
    "                           \"ecomnia\"]\n",
    "er=['Error page','error','404 Page Not Found','URL Error.','','Access Denied','Access to this page has been denied.',\n",
    "    'Privacy error','Access to website is restricted','Access to this website has been denied','403 Forbidden',\n",
    "    'Just a moment...']\n",
    "e='https://example.com/nonexistentpage'\n",
    "driver_info = [\n",
    "    {\"name\": \"driver1\", \"position\": \"0,0\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver2\", \"position\": \"400,0\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver3\", \"position\": \"800,0\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver4\", \"position\": \"1200,0\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver5\", \"position\": \"0,200\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver6\", \"position\": \"400,200\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver7\", \"position\": \"800,200\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver8\", \"position\": \"1200,200\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver9\", \"position\": \"0,400\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver10\", \"position\": \"400,400\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver11\", \"position\": \"800,400\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver12\", \"position\": \"1200,400\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver13\", \"position\": \"0,600\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver14\", \"position\": \"400,600\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver15\", \"position\": \"800,600\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver16\", \"position\": \"1200,600\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver17\", \"position\": \"0,0\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver18\", \"position\": \"400,0\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver19\", \"position\": \"800,0\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver20\", \"position\": \"1200,0\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver21\", \"position\": \"0,200\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver22\", \"position\": \"400,200\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver23\", \"position\": \"800,200\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver24\", \"position\": \"1200,200\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver25\", \"position\": \"0,400\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver26\", \"position\": \"400,400\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver27\", \"position\": \"800,400\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver28\", \"position\": \"1200,400\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver29\", \"position\": \"0,600\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver30\", \"position\": \"400,600\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver31\", \"position\": \"800,600\", \"size\": \"400,200\"},\n",
    "    {\"name\": \"driver32\", \"position\": \"1200,600\", \"size\": \"400,200\"},\n",
    "\n",
    "]\n",
    "files=[]\n",
    "comment=['https://shoppingwaves.net/','https://link.shoplooks.com/index.php?','https://www.linkhaitao.com/index.php?',\n",
    "         'https://prices.com/','https://get.shophints.io/','https://www.shareasale.com/notactive.html?',\n",
    "         'https://links.flexoffers.com/invalid/','https://cj.dotomi.com/links-t','https://app.partnerboost.com/track?',\n",
    "         'https://click.linksynergy.com/deeplink?','https://www.google.com/','http://www.qksrv.net/media/offers/?','Dead End',\n",
    "         'Access Denied','https://de.trck.one/redir/clickGate.php?','https://www.awin1.com/cread.php?','https://cj.dotomi.com/']\n",
    "ROW_COUNT=4 #int(input(\"enter the number of rows in each iteration min = 1 and max = 8:\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68718990",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "276ed458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vpn(Geo):\n",
    "    #task\n",
    "    pyautogui.moveTo(149,1048, duration=1)\n",
    "    pyautogui.click()\n",
    "    time.sleep(2)    \n",
    "    #menu\n",
    "    pyautogui.moveTo(928,541, duration=1)\n",
    "    pyautogui.click()\n",
    "    #ser\n",
    "    pyautogui.moveTo(1445,204, duration=1)\n",
    "    pyautogui.click()\n",
    "    pyautogui.write(Geo)\n",
    "    #ci \n",
    "    pyautogui.moveTo(1394,267, duration=1)\n",
    "    pyautogui.click(clicks=2) \n",
    "    time.sleep(18)\n",
    "    #minn\n",
    "    pyautogui.moveTo(1048,151, duration=1)\n",
    "    pyautogui.click()\n",
    "    pyautogui.moveTo(149,1048, duration=1)\n",
    "    return Geo\n",
    "def dumb_compliance_checker(i):\n",
    "    def check_monetization_perimeter(url, monetization_perimeters):\n",
    "        query_params = url.split('?')\n",
    "        if len(query_params) > 1:\n",
    "            for perimeter in monetization_perimeters:\n",
    "                if perimeter.lower() in query_params[1].lower():\n",
    "                    return True\n",
    "        return False\n",
    "    def title(title, er):\n",
    "        title=title.split()\n",
    "        for word in er:\n",
    "            if word.lower() in [title.lower() for title in title] :\n",
    "                return True\n",
    "        return False\n",
    "    def commenting(url,comment):\n",
    "        for comments in comment:\n",
    "            if comments in url:\n",
    "                return True\n",
    "        return False\n",
    "    try:\n",
    "        j=0\n",
    "        for j in range(ROW_COUNT):\n",
    "                                    \n",
    "            if (urlunparse(urlparse(df.at[(i+j),'Home page url/loaded/'].rstrip('/').replace(\"www.\", \"\"))._replace(fragment='')) != urlunparse(urlparse(df.at[(i+j),'Home page url'].rstrip('/').replace(\"www.\", \"\"))._replace(fragment=''))):\n",
    "                df.loc[(i+j), ['Home page url/loaded/', 'Compliance url/loaded/']] = df.loc[(i+j), ['Compliance url/loaded/', 'Home page url/loaded/']].values\n",
    "                    \n",
    "            if urlunparse(urlparse(df.at[(i+j),'Cat page url/loaded/'].rstrip('/').replace(\"www.\", \"\"))._replace(fragment='')) != urlunparse(urlparse(df.at[(i+j),'Cat page url'].rstrip('/').replace(\"www.\", \"\"))._replace(fragment='')):\n",
    "                df.loc[(i+j), ['Cat page url/loaded/', 'Compliance url.1/loaded/']] = df.loc[(i+j), ['Compliance url.1/loaded/', 'Cat page url/loaded/']].values\n",
    "                    \n",
    "            if \"?\" in urlunparse(urlparse(df.at[(i+j),'Home page url/loaded/'].rstrip('/').replace(\"www.\", \"\"))._replace(fragment='')):\n",
    "                if \"?\" not in urlunparse(urlparse(df.at[(i+j),'Compliance url/loaded/'].rstrip('/').replace(\"www.\", \"\"))._replace(fragment='')):\n",
    "                    df.loc[(i+j), ['Home page url/loaded/', 'Compliance url/loaded/']] = df.loc[(i+j), ['Compliance url/loaded/', 'Home page url/loaded/']].values\n",
    "            if \"?\" in urlunparse(urlparse(df.at[(i+j),'Cat page url/loaded/'].rstrip('/').replace(\"www.\", \"\"))._replace(fragment='')):\n",
    "                if \"?\" not in urlunparse(urlparse(df.at[(i+j),'Compliance url.1/loaded/'].rstrip('/').replace(\"www.\", \"\"))._replace(fragment='')):\n",
    "                    df.loc[(i+j), ['Cat page url/loaded/', 'Compliance url.1/loaded/']] = df.loc[(i+j), ['Compliance url.1/loaded/', 'Cat page url/loaded/']].values   \n",
    "   \n",
    "            # normal links matching with comp\n",
    "            if (urlunparse(urlparse(df.at[(i+j),'Home page url/loaded/'])._replace(fragment='')) == urlunparse(urlparse(df.at[(i+j),'Compliance url/loaded/'])._replace(fragment=''))):\n",
    "                df.at[i + j, 'is_passed_home_page?'] = \"Y\"        \n",
    "            elif (urlunparse(urlparse(df.at[(i+j),'Home page url/loaded/'].split('?')[0])._replace(fragment='')) == urlunparse(urlparse(df.at[(i+j),'Compliance url/loaded/'])._replace(fragment=''))) :\n",
    "                df.at[i + j, 'is_passed_home_page?'] = \"Y\"\n",
    "            elif (urlunparse(urlparse(df.at[(i+j),'Compliance url/loaded/'].split('?')[0])._replace(fragment='')) == urlunparse(urlparse(df.at[(i+j),'Home page url/loaded/'])._replace(fragment='')) ) :\n",
    "                df.at[i + j, 'is_passed_home_page?'] = \"Y\"\n",
    "            elif (urlunparse(urlparse(df.at[(i+j),'Home page url/loaded/'].split('?')[0].rstrip('/').replace(\"www.\", \"\"))._replace(fragment='')) == urlunparse(urlparse(df.at[(i+j),'Compliance url/loaded/'].split('?')[0].rstrip('/').replace(\"www.\", \"\"))._replace(fragment=''))):\n",
    "                df.at[i + j, 'is_passed_home_page?'] = \"Y\"   \n",
    "            else:\n",
    "                df.at[i + j, 'is_passed_home_page?'] = ''\n",
    "            \n",
    "            #mon_check\n",
    "            if df.at[i + j, 'is_passed_home_page?'] == ('' or \"\" or 'NaN' or 'nan'):\n",
    "                df.at[i + j, 'is_moNetize_home_page?'] = ''\n",
    "            else:    \n",
    "                if check_monetization_perimeter(df.at[(i+j),'Compliance url/loaded/'], monetization_perimeters):\n",
    "                    df.at[i + j, 'is_moNetize_home_page?'] = \"Y\"\n",
    "                else:\n",
    "                    df.at[i + j, 'is_moNetize_home_page?'] = \"N\"\n",
    "\n",
    "                \n",
    "            # normal links matching with comp\n",
    "            if (urlunparse(urlparse(df.at[(i+j),'Cat page url/loaded/'])._replace(fragment='')) == urlunparse(urlparse(df.at[(i+j),'Compliance url.1/loaded/'])._replace(fragment=''))):\n",
    "                  df.at[i + j, 'is_passed_categorY_page?'] = \"Y\"    \n",
    "            elif (urlunparse(urlparse(df.at[(i+j),'Cat page url/loaded/'].split('?')[0])._replace(fragment='')) == urlunparse(urlparse(df.at[(i+j),'Compliance url.1/loaded/'])._replace(fragment=''))):\n",
    "                  df.at[i + j, 'is_passed_categorY_page?'] = \"Y\"\n",
    "            elif (urlunparse(urlparse(df.at[(i+j),'Compliance url.1/loaded/'].split('?')[0])._replace(fragment='')) == urlunparse(urlparse(df.at[(i+j),'Cat page url/loaded/'])._replace(fragment=''))):\n",
    "                  df.at[i + j, 'is_passed_categorY_page?'] = \"Y\"\n",
    "            elif (urlunparse(urlparse(df.at[(i+j),'Cat page url/loaded/'].split('?')[0].rstrip('/').replace(\"www.\", \"\"))._replace(fragment='')) == urlunparse(urlparse(df.at[(i+j),'Compliance url.1/loaded/'].split('?')[0].rstrip('/').replace(\"www.\", \"\"))._replace(fragment=''))): \n",
    "                  df.at[i + j, 'is_passed_categorY_page?'] = \"Y\"      \n",
    "            else:\n",
    "                df.at[i + j, 'is_passed_categorY_page?'] = ''\n",
    "\n",
    "            # mon_check\n",
    "            if df.at[i + j, 'is_passed_categorY_page?'] == ('' or \"\" or 'NaN' or 'nan'):\n",
    "                df.at[i + j, 'is_moNetize_categorY_page?'] = ''\n",
    "            else:    \n",
    "                if check_monetization_perimeter(df.at[(i+j),'Compliance url.1/loaded/'], monetization_perimeters):\n",
    "                    df.at[i + j, 'is_moNetize_categorY_page?'] = \"Y\"\n",
    "                else:\n",
    "                    df.at[i + j, 'is_moNetize_categorY_page?'] = \"N\"\n",
    "\n",
    "            # Error\n",
    "            if ((df.at[(i+j),'Compliance url/loaded/'] == \"Error\") or (df.at[(i+j),'Home page url/loaded/'] == \"Error\") or (df.at[(i+j),'Home page url/loaded/'].split('?')[0] == \"Error\") or (df.at[(i+j),'Compliance url/loaded/'].split('?')[0] == \"Error\")):\n",
    "                df.at[i + j, 'is_passed_home_page?'] = \"\"\n",
    "                df.at[i + j, 'is_moNetize_home_page?'] = \"N\"\n",
    "            if ((df.at[(i+j),'Compliance url/loaded/'] == e) or (df.at[(i+j),'Home page url/loaded/'] == e) or (df.at[(i+j),'Home page url/loaded/'].split('?')[0] == e) or (df.at[(i+j),'Compliance url/loaded/'].split('?')[0] == e)):\n",
    "                df.at[i + j, 'is_moNetize_home_page?'] = \"N\"\n",
    "                \n",
    "            if ((df.at[(i+j),'Compliance url.1/loaded/'] == \"Error\") or (df.at[(i+j),'Cat page url/loaded/'] == \"Error\") or (df.at[(i+j),'Cat page url/loaded/'].split('?')[0] == \"Error\") or (df.at[(i+j),'Compliance url.1/loaded/'].split('?')[0] == \"Error\")):\n",
    "                df.at[i + j, 'is_passed_categorY_page?'] = \"N\"\n",
    "                df.at[i + j, 'is_moNetize_categorY_page?'] = \"N\"\n",
    "            if ((df.at[(i+j),'Compliance url.1/loaded/'] == e) or (df.at[(i+j),'Cat page url/loaded/'] == e) or (df.at[(i+j),'Cat page url/loaded/'].split('?')[0] == e) or (df.at[(i+j),'Compliance url.1/loaded/'].split('?')[0] == e)):\n",
    "                df.at[i + j, 'is_passed_categorY_page?'] = \"N\"\n",
    "                df.at[i + j, 'is_moNetize_categorY_page?'] = \"N\" \n",
    "                \n",
    "            #Title \n",
    "            if title(df.at[(i+j),'Home page url/title/'],er) or title(df.at[(i+j),'Compliance url/title/'],er):\n",
    "                df.at[i + j, 'is_passed_home_page?'] = ''\n",
    "                df.at[i + j, 'is_moNetize_home_page?'] = ''\n",
    "            if title(df.at[(i+j),'Cat page url/title/'],er) or title(df.at[(i+j),'Compliance url.1/title/'],er): \n",
    "                df.at[i + j, 'is_passed_categorY_page?'] = ''\n",
    "                df.at[i + j, 'is_moNetize_categorY_page?'] = ''               \n",
    "                              \n",
    "            #WHY?\n",
    "            if df.at[(i+j),'Home page url/loaded/'] == '':\n",
    "                df.at[i + j, 'is_passed_home_page?'] = ''\n",
    "            if df.at[(i+j),'Compliance url/loaded/'] == '':\n",
    "                df.at[i + j, 'is_passed_home_page?'] = ''    \n",
    "            if df.at[(i+j),'Cat page url/loaded/'] == '':\n",
    "                df.at[i + j, 'is_passed_categorY_page?'] = ''  \n",
    "            if df.at[(i+j),'Compliance url.1/loaded/'] == '':\n",
    "                df.at[i + j, 'is_passed_categorY_page?'] = ''               \n",
    "            if df.at[(i+j),'Home page url/loaded/'] == ('' or \"\" or 'NaN' or 'nan'):\n",
    "                df.at[i + j, 'is_passed_home_page?'] = ''\n",
    "            if df.at[(i+j),'Compliance url/loaded/'] == ('' or \"\" or 'NaN' or 'nan'):\n",
    "                df.at[i + j, 'is_passed_home_page?'] = '' \n",
    "            if df.at[(i+j),'Cat page url/loaded/'] == ('' or \"\" or 'NaN' or 'nan'):\n",
    "                df.at[i + j, 'is_passed_categorY_page?'] = ''\n",
    "            if df.at[(i+j),'Compliance url.1/loaded/'] == ('' or \"\" or 'NaN' or 'nan'):\n",
    "                df.at[i + j, 'is_passed_categorY_page?'] = ''    \n",
    "            if df.at[i + j, 'is_passed_categorY_page?'] == '':\n",
    "                df.at[i + j, 'is_moNetize_categorY_page?'] = ''    \n",
    "            if df.at[i + j, 'is_passed_home_page?'] == '':\n",
    "                df.at[i + j, 'is_moNetize_home_page?'] = ''    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de719f33",
   "metadata": {},
   "source": [
    "# loding the web pages to fetch there URls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e855f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local\n",
      "united states\n",
      "4 rows done\n",
      "8 rows done\n",
      "12 rows done\n",
      "16 rows done\n",
      "20 rows done\n",
      "24 rows done\n",
      "28 rows done\n",
      "32 rows done\n",
      "36 rows done\n",
      "40 rows done\n",
      "44 rows done\n",
      "48 rows done\n",
      "52 rows done\n",
      "56 rows done\n",
      "60 rows done\n",
      "64 rows done\n",
      "68 rows done\n",
      "72 rows done\n",
      "76 rows done\n",
      "80 rows done\n",
      "84 rows done\n",
      "88 rows done\n",
      "92 rows done\n",
      "96 rows done\n",
      "100 rows done\n",
      "104 rows done\n",
      "108 rows done\n",
      "112 rows done\n",
      "116 rows done\n",
      "120 rows done\n",
      "124 rows done\n",
      "128 rows done\n",
      "132 rows done\n",
      "136 rows done\n",
      "140 rows done\n",
      "144 rows done\n",
      "148 rows done\n",
      "152 rows done\n",
      "156 rows done\n",
      "160 rows done\n",
      "164 rows done\n",
      "168 rows done\n",
      "172 rows done\n",
      "176 rows done\n",
      "180 rows done\n",
      "184 rows done\n",
      "188 rows done\n",
      "192 rows done\n",
      "196 rows done\n",
      "200 rows done\n",
      "204 rows done\n",
      "208 rows done\n",
      "212 rows done\n",
      "216 rows done\n",
      "220 rows done\n",
      "224 rows done\n",
      "228 rows done\n",
      "232 rows done\n",
      "236 rows done\n",
      "240 rows done\n",
      "244 rows done\n",
      "248 rows done\n",
      "252 rows done\n",
      "256 rows done\n",
      "260 rows done\n",
      "264 rows done\n",
      "268 rows done\n",
      "272 rows done\n",
      "276 rows done\n",
      "error in closing tab\n",
      "280 rows done\n",
      "284 rows done\n",
      "288 rows done\n",
      "292 rows done\n",
      "296 rows done\n",
      "error in closing tab\n",
      "300 rows done\n",
      "304 rows done\n",
      "308 rows done\n",
      "312 rows done\n",
      "316 rows done\n",
      "320 rows done\n",
      "324 rows done\n",
      "328 rows done\n",
      "332 rows done\n",
      "336 rows done\n",
      "340 rows done\n",
      "344 rows done\n",
      "348 rows done\n",
      "352 rows done\n",
      "356 rows done\n",
      "360 rows done\n",
      "364 rows done\n",
      "368 rows done\n",
      "372 rows done\n",
      "376 rows done\n",
      "380 rows done\n",
      "384 rows done\n",
      "388 rows done\n",
      "392 rows done\n",
      "396 rows done\n",
      "400 rows done\n",
      "404 rows done\n",
      "408 rows done\n",
      "412 rows done\n",
      "416 rows done\n",
      "420 rows done\n",
      "424 rows done\n",
      "428 rows done\n",
      "432 rows done\n",
      "436 rows done\n",
      "440 rows done\n",
      "444 rows done\n",
      "448 rows done\n",
      "452 rows done\n",
      "456 rows done\n",
      "460 rows done\n",
      "464 rows done\n",
      "468 rows done\n",
      "472 rows done\n",
      "476 rows done\n",
      "480 rows done\n",
      "484 rows done\n",
      "488 rows done\n",
      "492 rows done\n",
      "496 rows done\n",
      "500 rows done\n",
      "504 rows done\n",
      "508 rows done\n",
      "512 rows done\n",
      "516 rows done\n",
      "520 rows done\n",
      "524 rows done\n",
      "528 rows done\n",
      "532 rows done\n",
      "536 rows done\n",
      "540 rows done\n",
      "544 rows done\n",
      "548 rows done\n",
      "552 rows done\n",
      "556 rows done\n",
      "560 rows done\n",
      "564 rows done\n",
      "568 rows done\n",
      "572 rows done\n",
      "576 rows done\n",
      "580 rows done\n",
      "584 rows done\n",
      "588 rows done\n",
      "592 rows done\n",
      "596 rows done\n",
      "600 rows done\n",
      "604 rows done\n",
      "608 rows done\n",
      "612 rows done\n",
      "616 rows done\n",
      "620 rows done\n",
      "624 rows done\n",
      "628 rows done\n",
      "632 rows done\n",
      "636 rows done\n",
      "640 rows done\n",
      "644 rows done\n",
      "Window already closed\n",
      "648 rows done\n",
      "652 rows done\n",
      "656 rows done\n",
      "660 rows done\n",
      "664 rows done\n",
      "668 rows done\n",
      "672 rows done\n",
      "676 rows done\n",
      "680 rows done\n",
      "684 rows done\n",
      "688 rows done\n",
      "692 rows done\n",
      "696 rows done\n",
      "700 rows done\n",
      "704 rows done\n",
      "708 rows done\n",
      "712 rows done\n",
      "716 rows done\n",
      "720 rows done\n",
      "724 rows done\n",
      "728 rows done\n",
      "732 rows done\n",
      "736 rows done\n",
      "740 rows done\n",
      "744 rows done\n",
      "748 rows done\n",
      "752 rows done\n",
      "756 rows done\n",
      "760 rows done\n",
      "764 rows done\n",
      "768 rows done\n",
      "772 rows done\n",
      "776 rows done\n",
      "780 rows done\n",
      "784 rows done\n",
      "788 rows done\n",
      "792 rows done\n",
      "796 rows done\n",
      "800 rows done\n",
      "804 rows done\n",
      "808 rows done\n",
      "812 rows done\n",
      "816 rows done\n",
      "820 rows done\n",
      "824 rows done\n",
      "828 rows done\n",
      "832 rows done\n",
      "836 rows done\n",
      "840 rows done\n",
      "844 rows done\n",
      "848 rows done\n",
      "852 rows done\n",
      "856 rows done\n",
      "860 rows done\n",
      "864 rows done\n",
      "868 rows done\n",
      "872 rows done\n",
      "876 rows done\n",
      "880 rows done\n",
      "884 rows done\n",
      "888 rows done\n",
      "892 rows done\n",
      "896 rows done\n",
      "900 rows done\n",
      "904 rows done\n",
      "908 rows done\n",
      "912 rows done\n",
      "916 rows done\n",
      "920 rows done\n",
      "924 rows done\n",
      "928 rows done\n",
      "932 rows done\n",
      "936 rows done\n",
      "940 rows done\n",
      "944 rows done\n",
      "948 rows done\n",
      "952 rows done\n",
      "956 rows done\n",
      "960 rows done\n",
      "964 rows done\n",
      "968 rows done\n",
      "972 rows done\n",
      "976 rows done\n",
      "980 rows done\n",
      "984 rows done\n",
      "988 rows done\n",
      "992 rows done\n",
      "996 rows done\n",
      "1000 rows done\n",
      "1004 rows done\n",
      "1008 rows done\n",
      "1012 rows done\n",
      "1016 rows done\n",
      "1020 rows done\n",
      "1024 rows done\n",
      "1028 rows done\n",
      "1032 rows done\n",
      "1036 rows done\n",
      "1040 rows done\n",
      "1044 rows done\n",
      "1048 rows done\n",
      "1052 rows done\n",
      "1056 rows done\n",
      "1060 rows done\n",
      "1064 rows done\n",
      "1068 rows done\n",
      "1072 rows done\n",
      "1076 rows done\n",
      "1080 rows done\n",
      "1084 rows done\n",
      "1088 rows done\n",
      "1092 rows done\n",
      "1096 rows done\n",
      "1100 rows done\n",
      "1104 rows done\n",
      "1108 rows done\n",
      "1112 rows done\n",
      "1116 rows done\n",
      "1120 rows done\n",
      "1124 rows done\n",
      "1128 rows done\n",
      "1132 rows done\n",
      "1136 rows done\n",
      "1140 rows done\n",
      "1144 rows done\n",
      "1148 rows done\n",
      "1152 rows done\n",
      "1156 rows done\n",
      "1160 rows done\n",
      "1164 rows done\n",
      "1168 rows done\n",
      "1172 rows done\n",
      "1176 rows done\n",
      "1180 rows done\n",
      "1184 rows done\n",
      "1188 rows done\n",
      "1192 rows done\n",
      "1196 rows done\n",
      "1200 rows done\n",
      "1204 rows done\n",
      "1208 rows done\n",
      "1212 rows done\n",
      "1216 rows done\n",
      "1220 rows done\n",
      "1224 rows done\n",
      "1228 rows done\n",
      "1232 rows done\n",
      "1236 rows done\n",
      "1240 rows done\n",
      "1244 rows done\n",
      "1248 rows done\n",
      "1252 rows done\n",
      "1256 rows done\n",
      "1260 rows done\n",
      "1264 rows done\n",
      "1268 rows done\n",
      "1272 rows done\n",
      "1276 rows done\n",
      "1280 rows done\n",
      "1284 rows done\n",
      "1288 rows done\n",
      "1292 rows done\n",
      "1296 rows done\n",
      "1300 rows done\n",
      "1304 rows done\n",
      "1308 rows done\n",
      "1312 rows done\n",
      "1316 rows done\n",
      "1320 rows done\n",
      "1324 rows done\n",
      "1328 rows done\n",
      "1332 rows done\n",
      "1336 rows done\n",
      "1340 rows done\n",
      "1344 rows done\n",
      "1348 rows done\n",
      "1352 rows done\n",
      "1356 rows done\n",
      "1360 rows done\n",
      "1364 rows done\n",
      "1368 rows done\n",
      "1372 rows done\n",
      "1376 rows done\n",
      "1380 rows done\n",
      "1384 rows done\n",
      "1388 rows done\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "# Fetches URLs & title and stores them in list \n",
    "def URL_fetcher(data):     \n",
    "\n",
    "    # Create a list to store all the drivers\n",
    "    drivers = []\n",
    "    \n",
    "    def reset():\n",
    "        for driver_obj in drivers:\n",
    "            driver_obj.quit() \n",
    "\n",
    "    # Print the connected location\n",
    "    connected_location = 'Local'\n",
    "    print(connected_location)\n",
    "\n",
    "    # Starting page loading\n",
    "    for i in range(0, len(df), ROW_COUNT):\n",
    "        try:\n",
    "            c=0\n",
    "            d=0\n",
    "            for j in range(ROW_COUNT):\n",
    "                if i+c<=len(df):\n",
    "                    if len(drivers)==0:\n",
    "                        # Create and configure the drivers\n",
    "                        for info in driver_info[:ROW_COUNT*2]:\n",
    "                            chrome_options = Options()\n",
    "                            chrome_options.add_argument(f\"window-position={info['position']}\")\n",
    "                            chrome_options.add_argument(f\"window-size={info['size']}\")\n",
    "                            #chrome_options.add_argument('--headless=new')\n",
    "                            driver = webdriver.Chrome(options=chrome_options)\n",
    "                            drivers.append(driver)\n",
    "                    \n",
    "                     # Setting up VPN location\n",
    "                    try:\n",
    "                        if connected_location != geo['server'][geo['geo'] == df['code'][i+c]].values[0]:\n",
    "                            Geo = geo['server'][geo['geo'] == df['code'][i+c]].values[0]\n",
    "                            connected_location = vpn(Geo)\n",
    "                            print(connected_location)\n",
    "                    except:\n",
    "                        print('error while switching vpn')\n",
    "                    # Loading URL from Compliance url\n",
    "                    try: \n",
    "                        drivers[d].set_page_load_timeout(100)\n",
    "                        drivers[d].execute_script(f\"window.open('{df['Compliance url'][i+c]}');\")\n",
    "                    except TimeoutException as e:\n",
    "                        print(f\"error in opening {i+c}\")\n",
    "                        break    # Raising the exception\n",
    "                    # Loading URL from Home page url \n",
    "                    try:\n",
    "                        drivers[d].set_page_load_timeout(100)\n",
    "                        drivers[d].execute_script(f\"window.open('{df['Home page url'][i+c]}');\")\n",
    "                    except TimeoutException as e:\n",
    "                        print(f\"error in opening {i+c}\")\n",
    "                        break    # Raising the exception\n",
    "                    # Loading URL from Compliance url.1\n",
    "                    if df['is_passed_categorY_page?'][i+c] != \"N\":\n",
    "                        try: \n",
    "                            drivers[d+1].set_page_load_timeout(100)\n",
    "                            drivers[d+1].execute_script(f\"window.open('{df['Compliance url.1'][i+c]}');\")\n",
    "                        except TimeoutException as e:\n",
    "                            print(f\"error in opening {i+c}\")\n",
    "                            break    # Raising the exception\n",
    "                    else:\n",
    "                        drivers[d+1].execute_script(f\"window.open('https://example.com/nonexistentpage');\")\n",
    "                    # Loading URL from Cat page url\n",
    "                    if df['is_passed_categorY_page?'][i+c] != \"N\":\n",
    "                        try:\n",
    "                            drivers[d+1].set_page_load_timeout(100)\n",
    "                            drivers[d+1].execute_script(f\"window.open('{df['Cat page url'][i+c]}');\")\n",
    "                        except TimeoutException as e:\n",
    "                            print(f\"error in opening {i+c}\")\n",
    "                            break    # Raising the exception\n",
    "                    else:\n",
    "                        drivers[d+1].execute_script(f\"window.open('https://example.com/nonexistentpage');\")\n",
    "                    c+=1\n",
    "                    d+=2\n",
    "                    \n",
    "                    try: \n",
    "                        if j==(ROW_COUNT-1) or i==(len(df)-1) or i==(len(df)-2) or i==(len(df)-3) or i==(len(df)-4):\n",
    "                            time.sleep(20)\n",
    "                            counter=0\n",
    "                            adder=0\n",
    "                            for driver_obj in drivers:\n",
    "                                handles = driver_obj.window_handles[1:3]\n",
    "                                for x in handles:\n",
    "                                    driver_obj.switch_to.window(x)\n",
    "                                    try:\n",
    "                                        driver_obj.set_page_load_timeout(100)\n",
    "                                        WebDriverWait(driver_obj, 10).until(EC.visibility_of_element_located((By.TAG_NAME, 'body')))\n",
    "                                        if counter==0:\n",
    "                                            df.at[(i+adder),'Home page url/loaded/'] = driver_obj.current_url\n",
    "                                            df.at[(i+adder),'Home page url/title/'] = driver_obj.title\n",
    "                                        elif counter==1:\n",
    "                                            df.at[(i+adder),'Compliance url/loaded/'] = driver_obj.current_url\n",
    "                                            df.at[(i+adder),'Compliance url/title/'] = driver_obj.title\n",
    "                                        elif counter==2:\n",
    "                                            df.at[(i+adder),'Cat page url/loaded/'] = driver_obj.current_url\n",
    "                                            df.at[(i+adder),'Cat page url/title/'] = driver_obj.title\n",
    "                                        elif counter==3:\n",
    "                                            df.at[(i+adder),'Compliance url.1/loaded/'] = driver_obj.current_url\n",
    "                                            df.at[(i+adder),'Compliance url.1/title/'] = driver_obj.title\n",
    "\n",
    "                                        counter+=1\n",
    "                                        if counter==4:\n",
    "                                            adder+=1\n",
    "                                            counter=0\n",
    "                                        driver_obj.close()\n",
    "                                    except TimeoutException as e:\n",
    "                                        if counter==0:\n",
    "                                            df.at[(i+adder),'Home page url/loaded/'] = 'Error'\n",
    "                                            df.at[(i+adder),'Home page url/title/'] = 'Error'\n",
    "                                        elif counter==1:\n",
    "                                            df.at[(i+adder),'Compliance url/loaded/'] = 'Error'\n",
    "                                            df.at[(i+adder),'Compliance url/title/'] = 'Error'\n",
    "                                        elif counter==2:\n",
    "                                            df.at[(i+adder),'Cat page url/loaded/'] = 'Error'\n",
    "                                            df.at[(i+adder),'Cat page url/title/'] = 'Error'\n",
    "                                        elif counter==3:\n",
    "                                            df.at[(i+adder),'Compliance url.1/loaded/'] = 'Error'\n",
    "                                            df.at[(i+adder),'Compliance url.1/title/'] = 'Error'\n",
    "\n",
    "                                        counter+=1\n",
    "                                        if counter==3:\n",
    "                                            adder+=1\n",
    "                                        driver_obj.close()  \n",
    "                                try:        \n",
    "                                    driver_obj.switch_to.window(driver_obj.window_handles[0])\n",
    "                                except:\n",
    "                                    print('can not switch to tab 0')       \n",
    "                            try:\n",
    "                                for driver_obj in drivers:\n",
    "                                    if (len(driver_obj.window_handles) != 1) or (len(drivers)!=(ROW_COUNT*2)):\n",
    "                                        reset() \n",
    "                                        drivers = []\n",
    "                            except:\n",
    "                                print('error in closing tab')                                          \n",
    "                        else:\n",
    "                            pass   \n",
    "                    except:\n",
    "                        print('Window already closed')\n",
    "                        reset()\n",
    "                        drivers = []                  \n",
    "                else:\n",
    "                    pass           \n",
    "        except:\n",
    "            print(f\"Error in opening {i} to {i+ROW_COUNT}\")\n",
    "            reset()\n",
    "            drivers = []\n",
    "        try:\n",
    "            if i%ROW_COUNT==0:\n",
    "                dumb_compliance_checker(i)\n",
    "                print(f\"{i+ROW_COUNT} rows done\")\n",
    "        except:\n",
    "            print('error in compliances')    \n",
    "    \n",
    "        if  i==0:\n",
    "            timestamp = time.strftime(\"%Y%m%d%H%M%S\")\n",
    "            file_name = f\"Final_output_{timestamp}.xlsx\"\n",
    "            files.append(file_name)\n",
    "        df.to_excel(file_name, index=False)\n",
    "  \n",
    "        ##################################################################################################\n",
    "    # Closing all the drivers\n",
    "    reset()\n",
    "    drivers = []\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    print(f\"Time elapsed: {(end_time - start_time)/(60*60)} hours\")\n",
    "    return df\n",
    "# Call the function\n",
    "URL_fetcher(df)\n",
    "\n",
    "#For re-running the data that is not passed\n",
    "\n",
    "df = df[((df['is_moNetize_home_page?'] != 'N') & (df['is_moNetize_home_page?'] != 'Y')) | \n",
    "        ((df['is_moNetize_categorY_page?'] != 'N') & (df['is_moNetize_categorY_page?'] != 'Y')) | \n",
    "        ((df['is_passed_home_page?'] == 'Y') & (df['is_moNetize_home_page?'] == 'N')) | \n",
    "        ((df['is_passed_categorY_page?'] == 'Y') & (df['is_moNetize_categorY_page?'] == 'N')) ]\n",
    "df.to_excel('with_errors.xlsx', index=False)\n",
    "df = pd.read_excel('with_errors.xlsx')\n",
    "URL_fetcher(df)\n",
    "\n",
    "run = pd.read_excel(files[0])\n",
    "re_run = pd.read_excel(files[1])\n",
    "print(len(run))\n",
    "print(len(re_run))\n",
    "run.loc[((run['is_passed_home_page?'] == 'Y') & (run['is_moNetize_home_page?'] == 'N')), ['is_passed_home_page?', 'is_moNetize_home_page?']] = ''\n",
    "run.loc[((run['is_passed_categorY_page?'] == 'Y') & (run['is_moNetize_categorY_page?'] == 'N')),['is_passed_categorY_page?', 'is_moNetize_categorY_page?']] = ''\n",
    "\n",
    "run.to_excel('Y-N removed.xlsx', index=False)\n",
    "run = pd.read_excel('Y-N removed.xlsx')\n",
    "lookup_columns = ['is_moNetize_home_page?', 'is_moNetize_categorY_page?', 'is_passed_home_page?', 'is_passed_categorY_page?']\n",
    "\n",
    "# Perform lookup for empty strings in lookup_columns using re_run\n",
    "for col in lookup_columns:\n",
    "    mask = run[col] == ''  # Create a mask for empty strings in the column\n",
    "    run[col] = run[col].fillna(run['id'].map(re_run.set_index('id')[col]))\n",
    "\n",
    "# Output the final DataFrame to an Excel file\n",
    "run.to_excel('Post_rerun_Output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b3b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f3c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb9f846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed60e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e53aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeebbd8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f178467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cef38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e707a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d9a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae1887c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633aae44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9557c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819c744d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e6849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0c9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba580b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0984c1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b565f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af04727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f88346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9e9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
